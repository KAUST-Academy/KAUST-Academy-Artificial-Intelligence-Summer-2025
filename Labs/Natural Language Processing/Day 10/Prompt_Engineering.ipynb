{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "![image.png](https://i.imgur.com/a3uAqnb.png)\n",
    "\n",
    "# Prompt Engineering: Mastering the Art of AI Communication\n",
    "\n",
    "This notebook demonstrates the fundamentals of **Prompt Engineering** - the practice of designing effective prompts to get better outputs from Large Language Models (LLMs). We'll explore different techniques that can dramatically improve model performance without any training or fine-tuning!\n",
    "\n",
    "### **üìå The Core Idea: Prompt Engineering**\n",
    "Prompt engineering is like learning to communicate effectively with an AI. Just as you might phrase a question differently for a child versus a professor, we need to craft our prompts to get the best responses from AI models.\n",
    "\n",
    "**What we'll cover:**\n",
    "1. **Basic Prompting**: Simple, direct instructions\n",
    "2. **Few-shot Learning**: Providing examples to guide the model\n",
    "3. **Chain-of-Thought (CoT)**: Teaching the model to reason step-by-step\n",
    "4. **Zero-shot CoT**: Getting reasoning without examples\n",
    "\n",
    "We'll use high-quality models that work well on 8GB VRAM: **Meta-Llama-3.2-3B-Instruct** for instruction following and **microsoft/Phi-3-mini-4k-instruct** for reasoning tasks - both are significantly more capable than older models!"
   ],
   "id": "e3d690265dff2685"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-17T04:26:33.010307Z",
     "start_time": "2025-07-17T04:26:23.378452Z"
    }
   },
   "source": [
    "# Install required packages (run this first)\n",
    "# %pip install torch torchvision torchaudio transformers accelerate bitsandbytes\n",
    "\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Suppress transformers warnings for clean output\n",
    "import logging\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "print(\"üìö Prompt Engineering Lab Setup Complete!\")\n",
    "print(f\"üîß Using device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Prompt Engineering Lab Setup Complete!\n",
      "üîß Using device: GPU\n",
      "üíæ GPU Memory: 6.4GB\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1Ô∏è‚É£ Model Setup: High-Quality Models for 8GB VRAM\n",
    "\n",
    "For this lab, we'll use two state-of-the-art models optimized for performance:\n",
    "\n",
    "- **Meta-Llama-3.2-3B-Instruct**: A 3B parameter model with excellent instruction following\n",
    "- **Microsoft Phi-3-mini-4k-instruct**: A 3.8B parameter model optimized for reasoning\n",
    "\n",
    "Both models are:\n",
    "‚úÖ **High Quality**: Much better outputs than older models\n",
    "‚úÖ **8GB VRAM Compatible**: Using 4-bit quantization\n",
    "‚úÖ **Fast Inference**: Optimized for efficiency\n",
    "‚úÖ **Instruction Tuned**: Designed to follow prompts well\n",
    "\n",
    "These models represent the current state-of-the-art for efficient, high-quality language models!"
   ],
   "id": "ad4dea58251f60bb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T04:27:04.843131Z",
     "start_time": "2025-07-17T04:26:37.594984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def setup_quantization():\n",
    "    \"\"\"Setup 4-bit quantization for memory efficiency\"\"\"\n",
    "    return BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "    )\n",
    "\n",
    "def load_models():\n",
    "    \"\"\"Load our high-quality prompt engineering models\"\"\"\n",
    "\n",
    "    quantization_config = setup_quantization() if torch.cuda.is_available() else None\n",
    "\n",
    "    print(\"üîÑ Loading Llama-3.2-3B-Instruct for instruction following...\")\n",
    "    # Llama 3.2 3B Instruct - excellent for instruction following\n",
    "    llama_tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "    llama_model = AutoModelForCausalLM.from_pretrained(\n",
    "        \"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "        quantization_config=quantization_config,\n",
    "        device_map=\"auto\" if torch.cuda.is_available() else None,\n",
    "        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "        trust_remote_code=True,\n",
    "        attn_implementation=\"eager\"\n",
    "    )\n",
    "\n",
    "    print(\"üîÑ Loading Phi-3-mini for reasoning tasks...\")\n",
    "    # Phi-3-mini - use older revision to avoid cache issues\n",
    "    phi_tokenizer = AutoTokenizer.from_pretrained(\n",
    "        \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "        revision=\"main\"\n",
    "    )\n",
    "    phi_model = AutoModelForCausalLM.from_pretrained(\n",
    "        \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "        quantization_config=quantization_config,\n",
    "        device_map=\"auto\" if torch.cuda.is_available() else None,\n",
    "        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "        trust_remote_code=True,\n",
    "        attn_implementation=\"eager\",\n",
    "        revision=\"main\",\n",
    "        use_cache=False  # Disable cache to avoid compatibility issues\n",
    "    )\n",
    "\n",
    "    # Set padding tokens\n",
    "    if llama_tokenizer.pad_token is None:\n",
    "        llama_tokenizer.pad_token = llama_tokenizer.eos_token\n",
    "    if phi_tokenizer.pad_token is None:\n",
    "        phi_tokenizer.pad_token = phi_tokenizer.eos_token\n",
    "\n",
    "    print(\"‚úÖ High-quality models loaded successfully!\")\n",
    "    return llama_tokenizer, llama_model, phi_tokenizer, phi_model\n",
    "\n",
    "# Load the models\n",
    "llama_tokenizer, llama_model, phi_tokenizer, phi_model = load_models()"
   ],
   "id": "ee75c2ddef692d61",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Loading Llama-3.2-3B-Instruct for instruction following...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "adf356a5a41245cca0b6e46e98d4327f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Loading Phi-3-mini for reasoning tasks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "41284d43d7b04961b9d9030e3d934814"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ High-quality models loaded successfully!\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T04:27:28.565538Z",
     "start_time": "2025-07-17T04:27:28.550347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_llama_response(prompt, max_new_tokens=150, temperature=0.7):\n",
    "    \"\"\"Generate response using Llama-3.2-3B-Instruct\"\"\"\n",
    "\n",
    "    # Format prompt for Llama instruction format\n",
    "    formatted_prompt = f\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\n{prompt}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\"\n",
    "\n",
    "    inputs = llama_tokenizer(formatted_prompt, return_tensors=\"pt\", truncation=True)\n",
    "    if torch.cuda.is_available():\n",
    "        inputs = {k: v.cuda() for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = llama_model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=temperature,\n",
    "            do_sample=True,\n",
    "            pad_token_id=llama_tokenizer.eos_token_id,\n",
    "            eos_token_id=llama_tokenizer.eos_token_id,\n",
    "            use_cache=False\n",
    "        )\n",
    "\n",
    "    # Decode only the new tokens (response)\n",
    "    response = llama_tokenizer.decode(outputs[0][len(inputs['input_ids'][0]):], skip_special_tokens=True)\n",
    "    return response.strip()\n",
    "\n",
    "def generate_phi_response(prompt, max_new_tokens=150, temperature=0.7):\n",
    "    \"\"\"Generate response using Phi-3-mini\"\"\"\n",
    "\n",
    "    # Format prompt for Phi-3 instruction format\n",
    "    formatted_prompt = f\"<|user|>\\n{prompt}<|end|>\\n<|assistant|>\\n\"\n",
    "\n",
    "    inputs = phi_tokenizer(formatted_prompt, return_tensors=\"pt\", truncation=True)\n",
    "    if torch.cuda.is_available():\n",
    "        inputs = {k: v.cuda() for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = phi_model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=temperature,\n",
    "            do_sample=True,\n",
    "            pad_token_id=phi_tokenizer.eos_token_id,\n",
    "            eos_token_id=phi_tokenizer.eos_token_id,\n",
    "            use_cache=False  # Disable cache to avoid compatibility issues\n",
    "        )\n",
    "\n",
    "    # Decode only the new tokens (response)\n",
    "    response = phi_tokenizer.decode(outputs[0][len(inputs['input_ids'][0]):], skip_special_tokens=True)\n",
    "    return response.strip()\n",
    "\n",
    "def display_comparison(title, prompts_and_responses):\n",
    "    \"\"\"Display a nice comparison of different prompting approaches\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üéØ {title}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    for i, (prompt_type, prompt, response) in enumerate(prompts_and_responses, 1):\n",
    "        print(f\"\\nüìù Approach {i}: {prompt_type}\")\n",
    "        print(f\"Prompt: {prompt}\")\n",
    "        print(f\"Response: {response}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "print(\"üõ†Ô∏è Helper functions ready!\")"
   ],
   "id": "afc91b471de67de7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõ†Ô∏è Helper functions ready!\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2Ô∏è‚É£ Basic Prompting: The Foundation\n",
    "\n",
    "Basic prompting is the simplest form of interaction with an LLM. You provide a direct instruction or question, and the model responds. The key is being **clear**, **specific**, and **concise**.\n",
    "\n",
    "### **üîπ Key Principles of Basic Prompting:**\n",
    "- **Be Specific**: Vague prompts lead to vague responses\n",
    "- **Provide Context**: Give the model enough information to understand your request\n",
    "- **Set Expectations**: Specify the format or type of response you want\n",
    "- **Use Clear Language**: Avoid ambiguity and complex sentence structures\n",
    "\n",
    "Let's see how different ways of asking the same question can yield very different results with our high-quality models!"
   ],
   "id": "d80587c8798d8f4b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T04:29:01.485498Z",
     "start_time": "2025-07-17T04:27:37.689038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"üöÄ Basic Prompting Examples\")\n",
    "\n",
    "# Example 1: Math Problem - Different levels of specificity\n",
    "math_prompts = [\n",
    "    (\"Vague\", \"Do some math\", \"\"),\n",
    "    (\"Basic\", \"What is 847 * 23?\", \"\"),\n",
    "    (\"Specific\", \"Calculate 847 multiplied by 23 and show your work step by step.\", \"\"),\n",
    "    (\"Very Specific\", \"Solve this multiplication problem step by step: 847 √ó 23 = ? Show each step of the calculation.\", \"\")\n",
    "]\n",
    "\n",
    "# Generate responses for math prompts using Phi-3 (better for math)\n",
    "for i, (prompt_type, prompt, _) in enumerate(math_prompts):\n",
    "    if prompt.strip() :\n",
    "        response = generate_phi_response(prompt)\n",
    "        math_prompts[i] = (prompt_type, prompt, response)\n",
    "\n",
    "# Filter out empty responses\n",
    "math_prompts = [(pt, p, r) for pt, p, r in math_prompts if r]\n",
    "\n",
    "display_comparison(\"Basic Prompting: Specificity Matters\", math_prompts)"
   ],
   "id": "28f0ac6bf424a0d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Basic Prompting Examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üéØ Basic Prompting: Specificity Matters\n",
      "============================================================\n",
      "\n",
      "üìù Approach 1: Vague\n",
      "Prompt: Do some math\n",
      "Response: As an AI, I don't perform tasks, but I can guide you on how to do some math. Let's say you want to add two numbers, 7 and 3:\n",
      "\n",
      "\n",
      "1. Write down the numbers, one under the other with the units aligned:\n",
      "\n",
      "```\n",
      "\n",
      "  7\n",
      "\n",
      "+ 3\n",
      "\n",
      "```\n",
      "\n",
      "\n",
      "2. Add the units column: 7 + 3 equals 10.\n",
      "\n",
      "3. Write down the sum:\n",
      "\n",
      "```\n",
      "\n",
      "  7\n",
      "\n",
      "+ 3\n",
      "\n",
      "----\n",
      "\n",
      "10\n",
      "\n",
      "```\n",
      "\n",
      "\n",
      "There you have it; the sum of 7 and 3 is 10.\n",
      "----------------------------------------\n",
      "\n",
      "üìù Approach 2: Basic\n",
      "Prompt: What is 847 * 23?\n",
      "Response: 847 multiplied by 23 equals 19,881.\n",
      "----------------------------------------\n",
      "\n",
      "üìù Approach 3: Specific\n",
      "Prompt: Calculate 847 multiplied by 23 and show your work step by step.\n",
      "Response: To multiply 847 by 23, we'll use the long multiplication method. Here's how it works step by step:\n",
      "\n",
      "\n",
      "```\n",
      "\n",
      "    847\n",
      "\n",
      "  x  23\n",
      "\n",
      "  ------\n",
      "\n",
      "    2541    (847 multiplied by 3, the units place)\n",
      "\n",
      " +1694      (847 multiplied by 20, which is 2 with one zero added to it, representing the tens place)\n",
      "\n",
      "  ------\n",
      "\n",
      "   19581\n",
      "\n",
      "```\n",
      "\n",
      "\n",
      "First, we multiply the units:\n",
      "\n",
      "847 x 3 = 2541\n",
      "----------------------------------------\n",
      "\n",
      "üìù Approach 4: Very Specific\n",
      "Prompt: Solve this multiplication problem step by step: 847 √ó 23 = ? Show each step of the calculation.\n",
      "Response: To solve the multiplication problem 847 √ó 23 step by step, we'll use the standard algorithm for multiplication:\n",
      "\n",
      "\n",
      "Step 1: Multiply the ones place digits.\n",
      "\n",
      "7 (ones place of 847) √ó 3 (ones place of 23) = 21. Write down the 1 in the ones place of the answer and carry over the 2 to the tens place.\n",
      "\n",
      "\n",
      "Step 2: Multiply the tens place digit of the first number by the ones place digit of the second number.\n",
      "\n",
      "4 (tens place of 847) √ó 3 (ones place of 23) = 12.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T04:30:06.110241Z",
     "start_time": "2025-07-17T04:29:01.604990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example 2: Creative Writing - Context and Format Matter\n",
    "writing_prompts = [\n",
    "    (\"No Context\", \"Write a story.\", \"\"),\n",
    "    (\"Some Context\", \"Write a short story about a robot discovering emotions.\", \"\"),\n",
    "    (\"Clear Context & Format\", \"Write a 100-word story about a robot who discovers emotions when it finds an abandoned kitten. Include dialogue and end with a hopeful tone.\", \"\")\n",
    "]\n",
    "\n",
    "for i, (prompt_type, prompt, _) in enumerate(writing_prompts):\n",
    "    response = generate_llama_response(prompt, temperature=0.8)\n",
    "    writing_prompts[i] = (prompt_type, prompt, response)\n",
    "\n",
    "display_comparison(\"Basic Prompting: Context and Format\", writing_prompts)"
   ],
   "id": "db607a93fb3769a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üéØ Basic Prompting: Context and Format\n",
      "============================================================\n",
      "\n",
      "üìù Approach 1: No Context\n",
      "Prompt: Write a story.\n",
      "Response: In the small town of Willow Creek, nestled in the heart of the Whispering Woods, a mysterious stranger arrived one day. No one knew where he came from, but his worn leather boots and dusty coat spoke of a long and winding journey. He walked into the local tavern, the Red Oak Inn, with a purposeful stride, his eyes scanning the room as if searching for something.\n",
      "\n",
      "The patrons fell silent, sizing him up. The bartender, a stout woman with a warm smile, poured him a mug of ale without a word. \"You look like someone who's seen some miles,\" she said, nodding at his weathered boots.\n",
      "\n",
      "The stranger took a sip of the ale, his eyes locking onto a figure in the corner of the\n",
      "----------------------------------------\n",
      "\n",
      "üìù Approach 2: Some Context\n",
      "Prompt: Write a short story about a robot discovering emotions.\n",
      "Response: **Metal Heart**\n",
      "\n",
      "In a world of wires and circuits, a lone robot stood on the factory floor, surrounded by his fellow machines. For years, he had processed data, assembled products, and followed instructions without hesitation. But something was different this day. As he worked on a particularly intricate assembly line, he felt... something.\n",
      "\n",
      "At first, he thought it was just a glitch. A minor system failure. But as he continued to work, the sensation grew. It was a tingling in his digital heart, a buzzing in his circuits. He couldn't explain it, but it felt... happy.\n",
      "\n",
      "The robot's designation was Zeta-5432, but his creators had never programmed him to experience emotions. He was designed for efficiency, not\n",
      "----------------------------------------\n",
      "\n",
      "üìù Approach 3: Clear Context & Format\n",
      "Prompt: Write a 100-word story about a robot who discovers emotions when it finds an abandoned kitten. Include dialogue and end with a hopeful tone.\n",
      "Response: \"Beep boop, I've found something,\" the robot announced, its electronic eyes fixed on the tiny ball of fluff. The kitten, no more than a few weeks old, had been left abandoned on the factory floor. The robot's advanced sensors detected its heartbeat, and it felt... something. A spark of warmth, a flutter in its digital chest. \"I... I think I feel... happiness?\" the robot stammered. \"Affirmative,\" it corrected itself. \"I feel happiness.\" The robot gently picked up the kitten and cradled it in its metal arms. \"Perhaps I'm not just metal and wires,\" it said, its voice filled with wonder. \"Perhaps I'm alive.\"\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T04:31:11.127159Z",
     "start_time": "2025-07-17T04:30:06.217376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example 3: Information Retrieval - Precision in Questions\n",
    "info_prompts = [\n",
    "    (\"Broad\", \"Tell me about climate change.\", \"\"),\n",
    "    (\"Focused\", \"What are the three main causes of climate change?\", \"\"),\n",
    "    (\"Targeted\", \"List the top 3 human activities that contribute most to greenhouse gas emissions, with a brief explanation for each.\", \"\")\n",
    "]\n",
    "\n",
    "for i, (prompt_type, prompt, _) in enumerate(info_prompts):\n",
    "    response = generate_llama_response(prompt)\n",
    "    info_prompts[i] = (prompt_type, prompt, response)\n",
    "\n",
    "display_comparison(\"Basic Prompting: Question Precision\", info_prompts)"
   ],
   "id": "514fea91c6ac18d1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üéØ Basic Prompting: Question Precision\n",
      "============================================================\n",
      "\n",
      "üìù Approach 1: Broad\n",
      "Prompt: Tell me about climate change.\n",
      "Response: Climate change is a complex and multifaceted issue that affects the entire planet. Here's a comprehensive overview:\n",
      "\n",
      "**What is climate change?**\n",
      "\n",
      "Climate change refers to the long-term warming of the planet, which is primarily caused by the increasing levels of greenhouse gases in the Earth's atmosphere. These gases, such as carbon dioxide (CO2), methane (CH4), and water vapor, trap heat from the sun, leading to a rise in global temperatures.\n",
      "\n",
      "**Causes of climate change**\n",
      "\n",
      "There are several key factors contributing to climate change:\n",
      "\n",
      "1. **Greenhouse gases**: The burning of fossil fuels (coal, oil, and gas) for energy releases large amounts of CO2 into the atmosphere, while deforestation and agriculture release methane and nit\n",
      "----------------------------------------\n",
      "\n",
      "üìù Approach 2: Focused\n",
      "Prompt: What are the three main causes of climate change?\n",
      "Response: The three main causes of climate change are widely accepted by the scientific community and are based on extensive research and data. These causes can be broadly categorized into three main areas:\n",
      "\n",
      "1. **Carbon dioxide (CO2) emissions from fossil fuel combustion**: The burning of fossil fuels such as coal, oil, and natural gas for energy releases large amounts of CO2 into the atmosphere, leading to global warming. This is the primary cause of climate change, accounting for about 65% of human-caused greenhouse gas emissions.\n",
      "2. **Deforestation and land-use changes**: The clearance of forests for agriculture, urbanization, and other purposes releases carbon stored in trees and reduces the ability of forests to act as carbon sinks. Deforestation and land-use changes are\n",
      "----------------------------------------\n",
      "\n",
      "üìù Approach 3: Targeted\n",
      "Prompt: List the top 3 human activities that contribute most to greenhouse gas emissions, with a brief explanation for each.\n",
      "Response: Here are the top 3 human activities that contribute most to greenhouse gas emissions, along with a brief explanation for each:\n",
      "\n",
      "1. **Electricity generation and use (42% of global GHG emissions)**\n",
      "\n",
      "The majority of electricity is generated from fossil fuels (coal, natural gas, and oil) through the process of combustion. This releases carbon dioxide (CO2), methane (CH4), and other greenhouse gases into the atmosphere. The burning of fossil fuels for electricity generation is the largest contributor to human-caused greenhouse gas emissions, accounting for approximately 42% of global emissions.\n",
      "\n",
      "2. **Agriculture and livestock (14% of global GHG emissions)**\n",
      "\n",
      "Agriculture, including the production of meat, especially beef, and the\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3Ô∏è‚É£ Few-shot Learning: Learning by Example\n",
    "\n",
    "Few-shot learning is like showing someone examples before asking them to do a task. Instead of just giving instructions, we provide the model with **examples** of the input-output pattern we want it to follow.\n",
    "\n",
    "### **üîπ The Power of Examples:**\n",
    "- **Pattern Recognition**: The model learns the desired format and style\n",
    "- **Consistency**: Examples help ensure consistent output structure\n",
    "- **Complex Tasks**: Enables the model to handle tasks that are hard to describe in words\n",
    "- **Quality Control**: Examples set the standard for response quality\n",
    "\n",
    "### **üîπ Few-shot Structure:**\n",
    "- Example 1: [Input] ‚Üí [Expected Output]\n",
    "- Example 2: [Input] ‚Üí [Expected Output]\n",
    "- Example 3: [Input] ‚Üí [Expected Output]\n",
    "- Now do this: [Your actual input] ‚Üí [Model generates output]\n",
    "\n",
    "Our high-quality models excel at pattern recognition, making few-shot learning extremely effective!"
   ],
   "id": "8b779a7c398a1697"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T04:31:17.793314Z",
     "start_time": "2025-07-17T04:31:11.216988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"üéØ Few-shot Learning Examples\")\n",
    "\n",
    "# Example 1: Sentiment Analysis with Few-shot\n",
    "few_shot_sentiment_prompt = \"\"\"\n",
    "Review: \"This restaurant exceeded all my expectations! Amazing food and service.\"\n",
    "Sentiment: Positive\n",
    "\n",
    "Review: \"Terrible experience. Cold food, rude staff, overpriced.\"\n",
    "Sentiment: Negative\n",
    "\n",
    "Review: \"It was decent. Nothing special but not bad either.\"\n",
    "Sentiment: Neutral\n",
    "\n",
    "Classify the sentiment of the following review as Positive, Negative, or Neutral, using the previous examples:\n",
    "\n",
    "Review: \"The program barely works, but there is no alternative\"\n",
    "Sentiment:\"\"\"\n",
    "\n",
    "# Compare with zero-shot\n",
    "zero_shot_sentiment_prompt = \"\"\"\n",
    "Classify the sentiment of this review as Positive, Negative, or Neutral:\n",
    "\n",
    "Review: \"The program barely works, but there is no alternative\"\n",
    "Sentiment:\"\"\"\n",
    "\n",
    "sentiment_responses = [\n",
    "    (\"Zero-shot\", zero_shot_sentiment_prompt, \"\"),\n",
    "    (\"Few-shot\", few_shot_sentiment_prompt, \"\")\n",
    "]\n",
    "\n",
    "for i, (approach, prompt, _) in enumerate(sentiment_responses):\n",
    "    response = generate_llama_response(prompt, max_new_tokens=30)\n",
    "    sentiment_responses[i] = (approach, \"Software review sentiment\", response)\n",
    "\n",
    "display_comparison(\"Few-shot vs Zero-shot: Sentiment Analysis\", sentiment_responses)"
   ],
   "id": "631351ec8d9e229d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Few-shot Learning Examples\n",
      "\n",
      "============================================================\n",
      "üéØ Few-shot vs Zero-shot: Sentiment Analysis\n",
      "============================================================\n",
      "\n",
      "üìù Approach 1: Zero-shot\n",
      "Prompt: Software review sentiment\n",
      "Response: I would classify the sentiment of this review as Negative.\n",
      "----------------------------------------\n",
      "\n",
      "üìù Approach 2: Few-shot\n",
      "Prompt: Software review sentiment\n",
      "Response: Based on the examples provided, I would classify the sentiment of the review as Negative. This is because the review mentions a negative aspect (the program not\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T04:31:49.577880Z",
     "start_time": "2025-07-17T04:31:17.824451Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example 2: Code Documentation with Few-shot\n",
    "few_shot_code_prompt = \"\"\"\n",
    "Function: def add_numbers(a, b): return a + b\n",
    "Documentation: Adds two numbers together and returns the result. Parameters: a (int/float), b (int/float). Returns: sum of a and b.\n",
    "\n",
    "Function: def find_max(numbers): return max(numbers)\n",
    "Documentation: Finds the maximum value in a list of numbers. Parameters: numbers (list). Returns: maximum value from the list.\n",
    "\n",
    "Using the previous two examples as valid documentation, generate documentation for the following function:\n",
    "\n",
    "Function: def validate_email(email): return \"@\" in email and \".\" in email.split(\"@\")[1]\n",
    "\"\"\"\n",
    "\n",
    "zero_shot_code_prompt = \"\"\"\n",
    "Generate documentation for this Python function:\n",
    "\n",
    "Function: def validate_email(email): return \"@\" in email and \".\" in email.split(\"@\")[1]\n",
    "Documentation:\"\"\"\n",
    "\n",
    "code_responses = [\n",
    "    (\"Zero-shot\", zero_shot_code_prompt, \"\"),\n",
    "    (\"Few-shot\", few_shot_code_prompt, \"\")\n",
    "]\n",
    "\n",
    "for i, (approach, prompt, _) in enumerate(code_responses):\n",
    "    response = generate_phi_response(prompt, max_new_tokens=80)\n",
    "    code_responses[i] = (approach, \"Email validation function\", response)\n",
    "\n",
    "display_comparison(\"Few-shot vs Zero-shot: Code Documentation\", code_responses)"
   ],
   "id": "d179f8eba8a3476d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üéØ Few-shot vs Zero-shot: Code Documentation\n",
      "============================================================\n",
      "\n",
      "üìù Approach 1: Zero-shot\n",
      "Prompt: Email validation function\n",
      "Response: ### Function Documentation: `validate_email`\n",
      "\n",
      "#### Function Signature\n",
      "```python\n",
      "def validate_email(email: str) -> bool:\n",
      "```\n",
      "\n",
      "#### Description\n",
      "The `validate_email` function is designed to check if a given string `email` is a valid email address. A valid email address, for the purpose of this function, is defined as a string\n",
      "----------------------------------------\n",
      "\n",
      "üìù Approach 2: Few-shot\n",
      "Prompt: Email validation function\n",
      "Response: Function: def validate_email(email):\n",
      "    # Validates whether the provided string is a valid email address\n",
      "    # Parameters:\n",
      "    #   email (str): The email address to be validated.\n",
      "    # Returns:\n",
      "    #   bool: True if the email address is valid, False otherwise.\n",
      "    # Validation criteria:\n",
      "    #   - The\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T04:32:04.940467Z",
     "start_time": "2025-07-17T04:31:49.645364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example 3: Complex Pattern - Data Analysis Summary\n",
    "few_shot_analysis_prompt = \"\"\"\n",
    "Dataset: Customer satisfaction survey (n=500, satisfaction score 4.2/5, 85% would recommend)\n",
    "Summary: HIGH SATISFACTION | Score: 4.2/5 | Recommendation rate: 85% | Sample: 500 customers | Action: Maintain current service quality\n",
    "\n",
    "Dataset: Website performance metrics (avg load time 2.1s, bounce rate 35%, conversion 3.2%)\n",
    "Summary: NEEDS IMPROVEMENT | Load time: 2.1s (slow) | Bounce rate: 35% (high) | Conversion: 3.2% | Action: Optimize page speed\n",
    "\n",
    "Using the previous two datasets as examples, please create a summary for the following dataset, use the same Summary format that was shown above.\n",
    "Dataset: Sales quarterly report (Q3 revenue $2.1M, 15% growth, target was $2M, top product: Software licenses)\n",
    "\"\"\"\n",
    "\n",
    "response = generate_llama_response(few_shot_analysis_prompt, max_new_tokens=80)\n",
    "print(f\"\\nüìä Few-shot Data Analysis Summary:\")\n",
    "print(f\"Input: Sales quarterly report with revenue, growth, and target data\")\n",
    "print(f\"Output: {response}\")"
   ],
   "id": "9c0f58408c9e54af",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Few-shot Data Analysis Summary:\n",
      "Input: Sales quarterly report with revenue, growth, and target data\n",
      "Output: Here is the summary:\n",
      "\n",
      " Dataset: Sales quarterly report (Q3 revenue $2.1M, 15% growth, target was $2M, top product: Software licenses)\n",
      "\n",
      "Summary: EXCELLENT PERFORMANCE | Revenue: $2.1M (exceeded target by 15%) | Growth: 15% (met target) | Top product: Software licenses (driving revenue\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4Ô∏è‚É£ Chain-of-Thought (CoT): Teaching the Model to Think\n",
    "\n",
    "Chain-of-Thought prompting is like asking someone to \"show their work\" on a complex problem. Instead of just getting the final answer, we guide the model to **think step-by-step** and show its reasoning process.\n",
    "\n",
    "### **üîπ Why CoT Works:**\n",
    "- **Complex Reasoning**: Breaks down difficult problems into manageable steps\n",
    "- **Improved Accuracy**: Step-by-step thinking reduces errors\n",
    "- **Transparency**: We can see how the model arrived at its conclusion\n",
    "- **Debugging**: If the answer is wrong, we can see where the reasoning failed\n",
    "\n",
    "### **üîπ CoT Structure:**\n",
    "**Problem:** [Complex question or task]\n",
    "**Let me think step by step:**\n",
    "\n",
    "1. [First reasoning step]\n",
    "2. [Second reasoning step]\n",
    "3. [Third reasoning step]\n",
    "\n",
    "...\n",
    "\n",
    "**Therefore,** [final answer]\n",
    "\n",
    "\n",
    "Our modern models have excellent reasoning capabilities and respond very well to CoT prompting!"
   ],
   "id": "2d64dd7f8dc30d3b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T04:34:11.199832Z",
     "start_time": "2025-07-17T04:32:04.992207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"üß† Chain-of-Thought Reasoning Examples\")\n",
    "\n",
    "# Example 1: Complex Math Word Problem\n",
    "direct_math_prompt = \"\"\"\n",
    "A company's revenue increased by 25% in Year 1, then decreased by 20% in Year 2. If they started with $800,000, what's their final revenue?\"\"\"\n",
    "\n",
    "cot_math_prompt = \"\"\"\n",
    "A company's revenue increased by 25% in Year 1, then decreased by 20% in Year 2. If they started with $800,000, what's their final revenue?\n",
    "\n",
    "Let me solve this step by step:\n",
    "1. Starting revenue: $800,000\n",
    "2. Year 1 increase of 25%: $800,000 √ó 1.25 = $1,000,000\n",
    "3. Year 2 decrease of 20%: $1,000,000 √ó 0.80 = $800,000\n",
    "Therefore, the final revenue is $800,000.\n",
    "\n",
    "Now solve this problem step by step:\n",
    "A store's profit margin was 15% in Q1, increased to 22% in Q2, then dropped to 18% in Q3. If Q1 sales were $500,000, and sales increased 10% each quarter, what was the profit in Q3?\n",
    "\n",
    "Let me solve this step by step:\"\"\"\n",
    "\n",
    "math_responses = [\n",
    "    (\"Direct\", \"A store's profit margin was 15% in Q1, increased to 22% in Q2, then dropped to 18% in Q3. If Q1 sales were $500,000, and sales increased 10% each quarter, what was the profit in Q3?\", \"\"),\n",
    "    (\"Chain-of-Thought\", cot_math_prompt, \"\")\n",
    "]\n",
    "\n",
    "for i, (approach, prompt, _) in enumerate(math_responses):\n",
    "    response = generate_phi_response(prompt, max_new_tokens=500)\n",
    "    math_responses[i] = (approach, \"Store profit calculation\", response)\n",
    "\n",
    "display_comparison(\"Chain-of-Thought: Complex Math Problem\", math_responses)"
   ],
   "id": "7dbdd8b9388e36e6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Chain-of-Thought Reasoning Examples\n",
      "\n",
      "============================================================\n",
      "üéØ Chain-of-Thought: Complex Math Problem\n",
      "============================================================\n",
      "\n",
      "üìù Approach 1: Direct\n",
      "Prompt: Store profit calculation\n",
      "Response: Let's calculate the sales for each quarter first:\n",
      "\n",
      "Q1 sales = $500,000\n",
      "\n",
      "For Q2, sales increased by 10%:\n",
      "Q2 sales = Q1 sales + (10% of Q1 sales)\n",
      "Q2 sales = $500,000 + (0.10 * $500,000)\n",
      "Q2 sales = $500,000 + $50,000\n",
      "Q2 sales = $550,000\n",
      "\n",
      "For Q3, sales increased by 10% again:\n",
      "Q3 sales = Q2 sales + (10% of Q2 sales)\n",
      "Q3 sales = $550,000 + (0.10 * $550,000)\n",
      "Q3 sales = $550,000 + $55,000\n",
      "Q3 sales = $605,000\n",
      "\n",
      "Now, let's calculate the profit for Q3 using the profit margin of 18%:\n",
      "Q3 profit = Q3 sales * Q3 profit margin\n",
      "Q3 profit = $605,000 * 0.18\n",
      "Q3 profit = $108,900\n",
      "\n",
      "So, the profit in Q3 was $108,900.\n",
      "----------------------------------------\n",
      "\n",
      "üìù Approach 2: Chain-of-Thought\n",
      "Prompt: Store profit calculation\n",
      "Response: 1. Q1 sales: $500,000\n",
      "2. Q2 sales increase of 10%: $500,000 √ó 1.10 = $550,000\n",
      "3. Q3 sales increase of 10%: $550,000 √ó 1.10 = $605,000\n",
      "4. Q1 profit margin: $500,000 √ó 0.15 = $75,000\n",
      "5. Q2 profit margin: $550,000 √ó 0.22 = $121,000\n",
      "6. Q3 profit margin: $605,000 √ó 0.18 = $109,900\n",
      "\n",
      "Therefore, the profit in Q3 was $109,900.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T04:34:55.930466Z",
     "start_time": "2025-07-17T04:34:11.356065Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example 2: Logical Reasoning\n",
    "direct_logic_prompt = \"\"\"\n",
    "If \"No cats are dogs\" and \"All pets in this house are cats,\" what can we conclude about dogs in this house?\"\"\"\n",
    "\n",
    "cot_logic_prompt = \"\"\"\n",
    "If \"No cats are dogs\" and \"All pets in this house are cats,\" what can we conclude about dogs in this house?\n",
    "\n",
    "Let me analyze this step by step:\n",
    "1. Given: \"No cats are dogs\" - This means cats and dogs are mutually exclusive categories\n",
    "2. Given: \"All pets in this house are cats\" - Every pet in the house belongs to the cat category\n",
    "3. From (1): If something is a cat, it cannot be a dog\n",
    "4. From (2): All pets are cats\n",
    "5. Combining (3) and (4): Since all pets are cats, and no cats are dogs, no pets can be dogs\n",
    "Therefore, there can be no dogs among the pets in this house.\n",
    "\n",
    "Now analyze this logic problem step by step:\n",
    "If \"All successful entrepreneurs take risks\" and \"Maria is risk-averse,\" what can we conclude about Maria's entrepreneurial success?\n",
    "\n",
    "Let me analyze this step by step:\"\"\"\n",
    "\n",
    "logic_responses = [\n",
    "    (\"Direct\", \"If 'All successful entrepreneurs take risks' and 'Maria is risk-averse,' what can we conclude about Maria's entrepreneurial success?\", \"\"),\n",
    "    (\"Chain-of-Thought\", cot_logic_prompt, \"\")\n",
    "]\n",
    "\n",
    "for i, (approach, prompt, _) in enumerate(logic_responses):\n",
    "    response = generate_phi_response(prompt, max_new_tokens=100)\n",
    "    logic_responses[i] = (approach, \"Entrepreneurship logic problem\", response)\n",
    "\n",
    "display_comparison(\"Chain-of-Thought: Logical Reasoning\", logic_responses)"
   ],
   "id": "b6d2e1815ff9b976",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üéØ Chain-of-Thought: Logical Reasoning\n",
      "============================================================\n",
      "\n",
      "üìù Approach 1: Direct\n",
      "Prompt: Entrepreneurship logic problem\n",
      "Response: From the given statements, we can infer that being risk-averse (not taking risks) is contrary to the behavior of successful entrepreneurs as described. Since Maria is risk-averse, it might be concluded that she does not match the typical profile of a successful entrepreneur as defined by the initial statement. However, this does not necessarily conclude her lack of entrepreneurial success, as success can be influenced by many other factors beyond risk-taking.\n",
      "----------------------------------------\n",
      "\n",
      "üìù Approach 2: Chain-of-Thought\n",
      "Prompt: Entrepreneurship logic problem\n",
      "Response: 1. Given: \"All successful entrepreneurs take risks\" - This means that taking risks is a common characteristic of successful entrepreneurs.\n",
      "2. Given: \"Maria is risk-averse\" - This means that Maria prefers to avoid risks.\n",
      "3. From (1): Since successful entrepreneurs take risks, and Maria is risk-averse, we can infer that her risk-averse nature may hinder her entrepreneurial\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T04:36:54.440638Z",
     "start_time": "2025-07-17T04:34:55.997907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example 3: Complex Decision Making with CoT\n",
    "decision_prompt = \"\"\"\n",
    "Should a small tech startup with 10 employees, $200K runway, and 6 months left accept a $50K investment offer that requires giving up 25% equity?\n",
    "\n",
    "Let me think through this decision step by step:\n",
    "1. Current situation analysis:\n",
    "   - Very limited runway (6 months)\n",
    "   - Small team size suggests early stage\n",
    "   - Need capital to survive and grow\n",
    "\n",
    "2. Investment offer evaluation:\n",
    "   - $50K extends runway by ~2-3 months (assuming $30K/month burn)\n",
    "   - 25% equity is significant for a small amount\n",
    "   - Valuation implied: $200K post-money\n",
    "\n",
    "3. Alternative considerations:\n",
    "   - Could they raise more money from other sources?\n",
    "   - Could they reduce burn rate instead?\n",
    "   - What's the growth trajectory?\n",
    "\n",
    "4. Risk assessment:\n",
    "   - Without funding: likely shutdown in 6 months\n",
    "   - With funding: more time but significant dilution\n",
    "   - Investor might provide valuable guidance\n",
    "\n",
    "Therefore, if no better alternatives exist, accepting the investment is likely the right choice to survive, despite the high dilution.\n",
    "\n",
    "Now help me think through this decision step by step:\n",
    "A freelance designer earning $80K/year is offered a full-time position at $70K/year plus benefits (health insurance worth $8K, 401k match worth $3K, paid vacation worth $5K). Should they take it?\n",
    "\n",
    "Let me think through this decision step by step:\"\"\"\n",
    "\n",
    "response = generate_llama_response(decision_prompt, max_new_tokens=400)\n",
    "print(f\"\\nü§î Chain-of-Thought Decision Making:\")\n",
    "print(f\"Problem: Freelancer considering full-time job offer\")\n",
    "print(f\"CoT Response: {response}\")"
   ],
   "id": "2b6a80df24bdadf2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§î Chain-of-Thought Decision Making:\n",
      "Problem: Freelancer considering full-time job offer\n",
      "CoT Response: Let's break down the decision step by step:\n",
      "\n",
      "**Current situation analysis:**\n",
      "\n",
      "* Freelance designer's current income: $80K/year\n",
      "* New job offer: $70K/year\n",
      "* Benefits: $11K/year (health insurance, 401k, paid vacation)\n",
      "* Net gain: $11K/year\n",
      "\n",
      "**Opportunity cost analysis:**\n",
      "\n",
      "* As a freelancer, the designer has the freedom to take on multiple clients and projects, potentially increasing their income.\n",
      "* With a full-time job, they'll have a steady income but limited flexibility to take on new projects or clients.\n",
      "* Opportunity cost: $70K/year (opportunity cost of not taking on freelance work) vs. $11K/year (net gain from the new job)\n",
      "\n",
      "**Wealth effect analysis:**\n",
      "\n",
      "* The designer will have a guaranteed income and benefits, but their wealth will be reduced by $10K/year ($70K - $11K).\n",
      "* However, they'll have a sense of security and stability, which can be valuable.\n",
      "\n",
      "**Risk assessment:**\n",
      "\n",
      "* Freelance work: uncertainty and risk of not having a steady income\n",
      "* Full-time job: stability and security, but limited flexibility and potential for boredom\n",
      "* Job offer: a reduction in overall wealth, but a guaranteed income and benefits\n",
      "\n",
      "**Trade-off analysis:**\n",
      "\n",
      "* The designer must weigh the benefits of stability and security against the potential loss of freedom and flexibility.\n",
      "* They must consider whether the benefits of the job (guaranteed income and benefits) outweigh the costs (reduced freedom and potential boredom).\n",
      "\n",
      "**Decision framework:**\n",
      "\n",
      "* Consider the importance of flexibility and autonomy in the designer's personal and professional life.\n",
      "* Weigh the benefits of stability and security against the potential drawbacks.\n",
      "* Think about the designer's long-term goals and priorities.\n",
      "\n",
      "**Decision:**\n",
      "\n",
      "Based on the analysis, the decision is not as clear-cut as it was for the startup. While the job offer provides stability and security, it also comes\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5Ô∏è‚É£ Zero-shot Chain-of-Thought: The Magic Phrase\n",
    "\n",
    "Zero-shot Chain-of-Thought is an incredibly simple yet powerful technique. By adding the phrase **\"Let's think step by step\"** to any prompt, we can often trigger step-by-step reasoning without providing any examples!\n",
    "\n",
    "### **üîπ The Magic of \"Let's think step by step\":**\n",
    "- **No Examples Needed**: Works without providing reasoning examples\n",
    "- **Universal Trigger**: Works across many different types of problems\n",
    "- **Emergent Behavior**: The model naturally breaks down complex problems\n",
    "- **Simple Implementation**: Just add one phrase to your existing prompts\n",
    "\n",
    "### **üîπ Zero-shot CoT Variations:**\n",
    "- \"Let's think step by step\"\n",
    "- \"Let's work through this systematically\"\n",
    "- \"Let me break this down step by step\"\n",
    "- \"Let's solve this step by step\"\n",
    "- \"Think about this carefully and systematically\"\n",
    "\n",
    "Our modern models respond exceptionally well to these reasoning triggers!"
   ],
   "id": "fbab0d88c0a4060c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T04:37:28.692299Z",
     "start_time": "2025-07-17T04:36:54.600552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"‚ú® Zero-shot Chain-of-Thought: The Magic Phrase\")\n",
    "\n",
    "# Example 1: Complex Calculation - With and Without the Magic Phrase\n",
    "regular_prompt = \"A rectangular garden is 15 meters long and 8 meters wide. If you want to put a fence around it and fence costs $12 per meter, how much will the total cost be?\"\n",
    "\n",
    "zero_shot_cot_prompt = \"A rectangular garden is 15 meters long and 8 meters wide. If you want to put a fence around it and fence costs $12 per meter, how much will the total cost be? Let's think step by step.\"\n",
    "\n",
    "math_zero_shot = [\n",
    "    (\"Regular Prompt\", regular_prompt, \"\"),\n",
    "    (\"Zero-shot CoT\", zero_shot_cot_prompt, \"\")\n",
    "]\n",
    "\n",
    "for i, (approach, prompt, _) in enumerate(math_zero_shot):\n",
    "    response = generate_phi_response(prompt, max_new_tokens=100)\n",
    "    math_zero_shot[i] = (approach, \"Garden fence problem\", response)\n",
    "\n",
    "display_comparison(\"Zero-shot CoT: Math Problem\", math_zero_shot)"
   ],
   "id": "17a234443885f50e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ú® Zero-shot Chain-of-Thought: The Magic Phrase\n",
      "\n",
      "============================================================\n",
      "üéØ Zero-shot CoT: Math Problem\n",
      "============================================================\n",
      "\n",
      "üìù Approach 1: Regular Prompt\n",
      "Prompt: Garden fence problem\n",
      "Response: To find the total cost of the fence, we first need to calculate the perimeter of the rectangular garden. The formula for the perimeter of a rectangle is:\n",
      "\n",
      "Perimeter = 2 * (Length + Width)\n",
      "\n",
      "Plugging in the given values:\n",
      "\n",
      "Perimeter = 2 * (15 m + 8 m)\n",
      "Perimeter = 2 * (23 m)\n",
      "Perimeter = 46 m\n",
      "\n",
      "Now that we\n",
      "----------------------------------------\n",
      "\n",
      "üìù Approach 2: Zero-shot CoT\n",
      "Prompt: Garden fence problem\n",
      "Response: Step 1: Determine the perimeter of the garden.\n",
      "The perimeter of a rectangle is calculated by adding the lengths of all its sides. For a rectangle, this is twice the length plus twice the width.\n",
      "\n",
      "Perimeter = 2 * length + 2 * width\n",
      "\n",
      "Step 2: Plug in the given values.\n",
      "Perimeter = 2 * 15 meters + 2 * 8 meters\n",
      "\n",
      "Step 3: Calculate the\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T04:38:33.435154Z",
     "start_time": "2025-07-17T04:37:28.704174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example 2: Strategy Problem\n",
    "regular_strategy_prompt = \"A new social media app has 1000 users after 3 months. Competitors have millions. What should they focus on to grow?\"\n",
    "\n",
    "zero_shot_strategy_prompt = \"A new social media app has 1000 users after 3 months. Competitors have millions. What should they focus on to grow? Let's think step by step.\"\n",
    "\n",
    "strategy_zero_shot = [\n",
    "    (\"Regular Prompt\", regular_strategy_prompt, \"\"),\n",
    "    (\"Zero-shot CoT\", zero_shot_strategy_prompt, \"\")\n",
    "]\n",
    "\n",
    "for i, (approach, prompt, _) in enumerate(strategy_zero_shot):\n",
    "    response = generate_llama_response(prompt, max_new_tokens=200)\n",
    "    strategy_zero_shot[i] = (approach, \"App growth strategy\", response)\n",
    "\n",
    "display_comparison(\"Zero-shot CoT: Strategy Problem\", strategy_zero_shot)\n"
   ],
   "id": "36c07eb557327cfd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üéØ Zero-shot CoT: Strategy Problem\n",
      "============================================================\n",
      "\n",
      "üìù Approach 1: Regular Prompt\n",
      "Prompt: App growth strategy\n",
      "Response: The classic problem of \"outgrowing your own app\"! Here are some strategies to help the new social media app grow and compete with established competitors:\n",
      "\n",
      "**Short-term (next 3-6 months)**\n",
      "\n",
      "1. **Improve the user experience**:\n",
      "\t* Enhance the app's user interface, usability, and overall feel to make it more engaging and enjoyable.\n",
      "\t* Add features that address user pain points, such as simplifying navigation, reducing clutter, and improving content discovery.\n",
      "\t* Focus on creating a seamless onboarding process to attract new users.\n",
      "2. **Content strategy**:\n",
      "\t* Develop a unique content strategy that resonates with your target audience.\n",
      "\t* Invest in high-quality, engaging content creation, such as videos, stories, and live streams.\n",
      "\t* Consider collaborating with influencers, creators, or brands to attract new users and promote your app.\n",
      "3. **Growth hacking**:\n",
      "\t* Leverage word-of-mouth by incentivizing existing users to invite\n",
      "----------------------------------------\n",
      "\n",
      "üìù Approach 2: Zero-shot CoT\n",
      "Prompt: App growth strategy\n",
      "Response: The classic \"underdog\" problem! Growing a social media app from 1000 users to compete with established players can be challenging, but with a focused strategy, it's achievable. Here's a step-by-step plan to help them grow:\n",
      "\n",
      "**Short-term goals (next 3-6 months)**\n",
      "\n",
      "1. **User Acquisition**:\n",
      "\t* **Content Marketing**: Develop a content strategy to attract new users. This could include:\n",
      "\t\t+ Creating engaging, high-quality content (text, images, videos) that resonates with your target audience.\n",
      "\t\t+ Collaborating with influencers or content creators in your niche.\n",
      "\t\t+ Utilizing paid advertising (Facebook, Instagram, Twitter, or LinkedIn ads) to reach a wider audience.\n",
      "\t* **Referral Program**: Implement a referral program to incentivize existing users to invite friends and family.\n",
      "2. **User Engagement**:\n",
      "\t* **Improve Onboarding**: Simplify the sign-up process, provide a clear and concise on\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T04:40:52.132339Z",
     "start_time": "2025-07-17T04:38:33.472001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Example 3: Technical Debugging\n",
    "regular_debug_prompt = \"My Python web app is running slowly. Users complain about 5-second load times. How should I troubleshoot this?\"\n",
    "\n",
    "zero_shot_debug_prompt = \"My Python web app is running slowly. Users complain about 5-second load times. How should I troubleshoot this? Let's think step by step.\"\n",
    "\n",
    "debug_zero_shot = [\n",
    "    (\"Regular Prompt\", regular_debug_prompt, \"\"),\n",
    "    (\"Zero-shot CoT\", zero_shot_debug_prompt, \"\")\n",
    "]\n",
    "\n",
    "for i, (approach, prompt, _) in enumerate(debug_zero_shot):\n",
    "    response = generate_phi_response(prompt, max_new_tokens=300)\n",
    "    debug_zero_shot[i] = (approach, \"Performance debugging\", response)\n",
    "\n",
    "display_comparison(\"Zero-shot CoT: Technical Problem\", debug_zero_shot)"
   ],
   "id": "9c971f83b32ff06",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üéØ Zero-shot CoT: Technical Problem\n",
      "============================================================\n",
      "\n",
      "üìù Approach 1: Regular Prompt\n",
      "Prompt: Performance debugging\n",
      "Response: To troubleshoot the slow performance of your Python web application:\n",
      "\n",
      "\n",
      "1. **Check Server Performance**: Ensure your server has sufficient resources (CPU, RAM) and isn't overloaded with requests.\n",
      "\n",
      "\n",
      "2. **Profiling**: Use a profiling tool like `cProfile` to identify the bottlenecks in your code. You would run your app with `cProfile` like this:\n",
      "\n",
      "\n",
      "```python\n",
      "\n",
      "import cProfile\n",
      "\n",
      "\n",
      "def run_app():\n",
      "\n",
      "    # Your app's main loop or function\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    profiler = cProfile.Profile()\n",
      "\n",
      "    profiler.enable()\n",
      "\n",
      "    run_app()\n",
      "\n",
      "    profiler.print_stats(sort='time')\n",
      "\n",
      "```\n",
      "\n",
      "\n",
      "3. **Optimize Database Queries**: If your app relies on a database, make sure all queries are optimized, and indexes are properly set.\n",
      "\n",
      "\n",
      "4. **Frontend Performance**: Check if the frontend is causing delays. Use tools like Google PageSpeed Insights to find and fix frontend issues.\n",
      "\n",
      "\n",
      "5. **Deployment**: Check if the live deployment might be causing delays due to scaling issues or misconfigurations.\n",
      "\n",
      "\n",
      "6. **External Libraries**: Review any third-party libraries or services\n",
      "----------------------------------------\n",
      "\n",
      "üìù Approach 2: Zero-shot CoT\n",
      "Prompt: Performance debugging\n",
      "Response: To troubleshoot the slow load times of your Python web app, follow these steps:\n",
      "\n",
      "\n",
      "1. **Profile Your Application**: Use a profiling tool such as cProfile to identify the functions that are taking the most time to execute. The output will show you which parts of your application are the slowest.\n",
      "\n",
      "\n",
      "2. **Analyze Database Queries**: If your application relies on a database, use tools like MySQL's EXPLAIN or an ORM's query analyzer to find slow queries. Optimize these queries by adding indexes or rewriting them for efficiency.\n",
      "\n",
      "\n",
      "3. **Optimize Python Code**: Look at the execution paths in your Python code where the bottlenecks are. Consider using more efficient data structures, algorithms, or leveraging libraries like NumPy for heavy computations.\n",
      "\n",
      "\n",
      "4. **Asynchronous Processing**: If your web app performs operations that can be done asynchronously, such as sending emails or API calls, consider using an asynchronous framework like Tornado or utilizing the `async` and `await` features in Python 3.7+.\n",
      "\n",
      "\n",
      "5. **Web Server Configuration**: Ensure that your web server is properly configured. Adjust the server settings to handle more concurrent connections efficiently.\n",
      "\n",
      "\n",
      "6. **Caching**: Implement caching for repetitive and heavy load data; this can vastly\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6Ô∏è‚É£ Advanced Prompt Engineering Techniques\n",
    "\n",
    "Now that we've mastered the basics, let's explore some advanced techniques that can further improve your prompt engineering skills:\n",
    "\n",
    "### **üîπ Role-Playing**: Having the AI adopt specific personas or expertise\n",
    "### **üîπ Output Formatting**: Controlling the structure and format of responses\n",
    "### **üîπ Constraint Setting**: Adding specific limitations or requirements\n",
    "### **üîπ Multi-step Prompting**: Breaking complex tasks into smaller steps\n",
    "### **üîπ Self-Correction**: Having the model check and improve its own work"
   ],
   "id": "6696ec8c37d40d32"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T04:42:16.669672Z",
     "start_time": "2025-07-17T04:40:52.293329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"üöÄ Advanced Prompt Engineering Techniques\")\n",
    "\n",
    "# Technique 1: Expert Role-Playing\n",
    "role_playing_prompt = \"\"\"\n",
    "You are a senior cybersecurity expert with 15 years of experience in enterprise security.\n",
    "A small business owner asks: \"I have 20 employees using personal devices for work. What are the top 3 security risks I should address immediately?\"\n",
    "\n",
    "Provide specific, actionable advice with your expert perspective:\"\"\"\n",
    "\n",
    "response = generate_llama_response(role_playing_prompt, max_new_tokens=400)\n",
    "print(f\"\\nüíº Expert Role-Playing Technique:\")\n",
    "print(f\"Response: {response}\")\n"
   ],
   "id": "cea474d3e316f7c3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Advanced Prompt Engineering Techniques\n",
      "\n",
      "üíº Expert Role-Playing Technique:\n",
      "Response: As a senior cybersecurity expert, I'd advise the small business owner to address the following top 3 security risks immediately:\n",
      "\n",
      "**Risk 1: Unsecured Personal Devices**\n",
      "\n",
      "With 20 employees using personal devices for work, there's a high risk of data breaches and unauthorized access to company data. To mitigate this risk:\n",
      "\n",
      "* **Implement a Bring Your Own Device (BYOD) policy**: Develop a clear policy that outlines the acceptable use of personal devices for work purposes. This should include guidelines on device management, security software, and data encryption.\n",
      "* **Require a company-owned device for sensitive work**: Consider requiring employees to use company-owned devices for sensitive work, such as handling customer data, financial transactions, or confidential information.\n",
      "* **Enforce strong security software**: Ensure all devices are running up-to-date security software, including antivirus, anti-malware, and a firewall. Regularly update and patch devices to prevent exploitation of known vulnerabilities.\n",
      "\n",
      "**Risk 2: Unsecured Wi-Fi Networks**\n",
      "\n",
      "Unsecured Wi-Fi networks pose a significant threat to the company's data and network. To address this risk:\n",
      "\n",
      "* **Implement a secure Wi-Fi network**: Ensure all company Wi-Fi networks are secured with WPA2 encryption and a strong password. Consider using a guest network for visitors and contractors to isolate their devices from the main network.\n",
      "* **Use a Virtual Private Network (VPN)**: Require employees to use a VPN when accessing the company network from personal devices or public Wi-Fi networks. This will encrypt all internet traffic and protect company data.\n",
      "* **Conduct regular network scans**: Regularly scan the network for vulnerabilities and weaknesses to identify areas for improvement.\n",
      "\n",
      "**Risk 3: Lack of Employee Awareness and Training**\n",
      "\n",
      "Employees are often the weakest link in an organization's security posture. To address this risk:\n",
      "\n",
      "* **Conduct regular security awareness training**: Provide regular security awareness training for all employees, covering topics such as phishing, password management, and data handling best practices.\n",
      "* **Develop a security\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T04:43:49.888950Z",
     "start_time": "2025-07-17T04:42:16.781070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Technique 2: Structured Output Formatting\n",
    "formatting_prompt = \"\"\"\n",
    "Analyze the pros and cons of electric vehicles vs gasoline cars. Format your response exactly as:\n",
    "\n",
    "ELECTRIC VEHICLES:\n",
    "Advantages:\n",
    "- [advantage 1 with brief explanation]\n",
    "- [advantage 2 with brief explanation]\n",
    "- [advantage 3 with brief explanation]\n",
    "Disadvantages:\n",
    "- [disadvantage 1 with brief explanation]\n",
    "- [disadvantage 2 with brief explanation]\n",
    "\n",
    "GASOLINE CARS:\n",
    "Advantages:\n",
    "- [advantage 1 with brief explanation]\n",
    "- [advantage 2 with brief explanation]\n",
    "- [advantage 3 with brief explanation]\n",
    "Disadvantages:\n",
    "- [disadvantage 1 with brief explanation]\n",
    "- [disadvantage 2 with brief explanation]\"\"\"\n",
    "\n",
    "response = generate_llama_response(formatting_prompt, max_new_tokens=500)\n",
    "print(f\"\\nüìã Structured Output Formatting:\")\n",
    "print(f\"Response: {response}\")\n"
   ],
   "id": "8f848bb8ba579a67",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã Structured Output Formatting:\n",
      "Response: Here's the analysis of the pros and cons of electric vehicles vs gasoline cars:\n",
      "\n",
      "**ELECTRIC VEHICLES:**\n",
      "\n",
      "Advantages:\n",
      "- **Zero Emissions**: Electric vehicles (EVs) produce no tailpipe emissions, reducing greenhouse gas emissions and air pollution in urban areas.\n",
      "- **Lower Operating Costs**: EVs are generally cheaper to run, with lower fuel costs (electricity is often less expensive than gasoline) and lower maintenance costs (fewer moving parts means less wear and tear).\n",
      "- **Smooth and Quiet Ride**: EVs have a smoother and quieter ride due to their electric motor, providing a more comfortable driving experience.\n",
      "\n",
      "Disadvantages:\n",
      "- **Limited Range**: EVs have a limited range (typically between 200-300 miles) before needing to be recharged, making long road trips more difficult.\n",
      "- **Charging Time**: Charging an EV can take several hours, although fast-charging technology is improving.\n",
      "\n",
      "**GASOLINE CARS:**\n",
      "\n",
      "Advantages:\n",
      "- **Longer Driving Range**: Gasoline cars have a longer driving range, allowing for longer road trips without the need for refueling.\n",
      "- **Faster Refueling**: Gasoline cars can be refueled quickly, taking just a few minutes to fill up.\n",
      "- **Wide Availability of Fueling Stations**: Gasoline stations are ubiquitous, making it easy to find a place to refuel.\n",
      "\n",
      "Disadvantages:\n",
      "- **Higher Operating Costs**: Gasoline cars are generally more expensive to run, with higher fuel costs and maintenance costs (more moving parts means more wear and tear).\n",
      "- **Environmental Impact**: Gasoline cars produce greenhouse gas emissions and contribute to air pollution, negatively impacting the environment.\n",
      "\n",
      "It's worth noting that both electric and gasoline cars have their own set of advantages and disadvantages, and the choice between them ultimately depends on individual preferences, driving habits, and lifestyle.\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T04:44:28.028918Z",
     "start_time": "2025-07-17T04:43:49.965774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Technique 3: Self-Correction\n",
    "self_correction_prompt = \"\"\"\n",
    "Solve this problem: \"If a train travels 240 km in 3 hours, what's its average speed in mph?\"\n",
    "\n",
    "First, provide your initial answer. Then, check your work and identify any errors. Finally, provide the corrected answer if needed.\n",
    "\n",
    "Initial solution:\"\"\"\n",
    "\n",
    "response = generate_phi_response(self_correction_prompt, max_new_tokens=1000)\n",
    "print(f\"\\nüîç Self-Correction Technique:\")\n",
    "print(f\"Response: {response}\")"
   ],
   "id": "a0a103245fc0306a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Self-Correction Technique:\n",
      "Response: Initial solution: The initial calculation for the average speed of the train is 240 km in 3 hours, which equals 80 km/h. To convert this to miles per hour (mph), we use the conversion factor that 1 km is approximately equal to 0.621371 miles. Thus, the average speed in mph is 80 km/h * 0œΩ21371 = 497.77 mph.\n",
      "\n",
      "Checking work: The initial calculation for the average speed in km/h is correct, but the conversion to mph is incorrect. The correct calculation should be 80 km/h * 0.621371 = 49.71 mph.\n",
      "\n",
      "Final corrected answer: The train's average speed is approximately 49.71 mph.\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T04:49:40.250298Z",
     "start_time": "2025-07-17T04:44:28.077476Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Technique 4: Multi-step Complex Problem Solving\n",
    "complex_prompt = \"\"\"\n",
    "You're helping a startup founder make a critical decision. They have these options:\n",
    "\n",
    "Option A: Raise $500K VC funding (30% equity, 18 months runway)\n",
    "Option B: Take $100K angel investment (8% equity, 6 months runway)\n",
    "Option C: Bootstrap with current $50K savings (3 months runway)\n",
    "\n",
    "Additional context: B2B SaaS product, 2 co-founders, early traction (10 paying customers, $2K MRR), growing 20% monthly.\n",
    "\n",
    "Please analyze this systematically:\n",
    "\n",
    "Step 1: Evaluate each option's financial implications\n",
    "Step 2: Assess the strategic value and risks\n",
    "Step 3: Consider timeline and growth requirements\n",
    "Step 4: Make a recommendation with reasoning\n",
    "\n",
    "Step 1 - Financial Analysis:\"\"\"\n",
    "\n",
    "response = generate_llama_response(complex_prompt, max_new_tokens=1500)\n",
    "print(f\"\\nüéØ Multi-step Complex Problem Solving:\")\n",
    "print(f\"Response: {response}\")"
   ],
   "id": "a4131b93d241adab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Multi-step Complex Problem Solving:\n",
      "Response: I'll analyze the options systematically.\n",
      "\n",
      "**Option A: Raise $500K VC funding (30% equity, 18 months runway)**\n",
      "\n",
      "* Financial implications:\n",
      "\t+ Additional $500K funding to extend the runway to 18 months\n",
      "\t+ 30% equity means the founders will give up 30% of their ownership\n",
      "\t+ Assuming a $1.67M valuation (500K / 0.3), the founders' pre-funding valuation is approximately $1.67M\n",
      "\t+ This funding will likely be used for growth, marketing, and operational expenses\n",
      "* Pros: More runway, access to VC expertise and network, potential for more effective use of resources\n",
      "* Cons: 30% equity cedes significant control and ownership to the VC, may require board involvement\n",
      "\n",
      "**Option B: Take $100K angel investment (8% equity, 6 months runway)**\n",
      "\n",
      "* Financial implications:\n",
      "\t+ Additional $100K funding to extend the runway to 6 months\n",
      "\t+ 8% equity means the founders will give up 8% of their ownership\n",
      "\t+ Assuming a $1.25M valuation (100K / 0.08), the founders' pre-investment valuation is approximately $1.25M\n",
      "\t+ This funding will likely be used for growth, marketing, and operational expenses\n",
      "* Pros: Smaller equity stake, more control, and potentially more agile decision-making\n",
      "* Cons: Smaller runway, limited access to VC expertise and network\n",
      "\n",
      "**Option C: Bootstrap with current $50K savings (3 months runway)**\n",
      "\n",
      "* Financial implications:\n",
      "\t+ No additional funding, but reduced runway to 3 months\n",
      "\t+ Current $50K savings will be depleted quickly\n",
      "\t+ No equity stake is given up\n",
      "* Pros: Minimal dilution, full control, and no external influence\n",
      "* Cons: Extremely limited runway, high risk of burnout or early exit\n",
      "\n",
      "**Step 2 - Strategic Value and Risks**\n",
      "\n",
      "* Option A: VC funding can provide access to expertise, network, and resources, which can be valuable for growth and scaling. However, it also comes with the risk of VC involvement in decision-making and potential dilution of ownership.\n",
      "* Option B: Angel investment offers a smaller equity stake and more control, but may limit the founders' access to resources and expertise.\n",
      "* Option C: Bootstrapping with minimal runway is the most conservative approach, but also the riskiest. It requires the founders to be extremely resourceful and efficient with their current resources.\n",
      "\n",
      "**Step 3 - Timeline and Growth Requirements**\n",
      "\n",
      "* All options require the founders to be prepared to operate in a very lean state for an extended period.\n",
      "* Option A assumes the founders can grow the business to justify the VC investment and achieve a higher valuation within 18 months.\n",
      "* Option B assumes the founders can grow the business to achieve a higher valuation within 6 months and justify the angel investment.\n",
      "* Option C assumes the founders can operate efficiently and make the most of their current resources to achieve growth without additional funding.\n",
      "\n",
      "**Step 4 - Recommendation with Reasoning**\n",
      "\n",
      "Based on the analysis, I would recommend **Option B: Take $100K angel investment (8% equity, 6 months runway)**. This option provides a moderate level of funding, allows for more control and agility, and reduces the risk of dilution. The founders can use the angel investment to drive growth and achieve a higher valuation within a shorter timeframe, which can help them secure additional funding or exit opportunities.\n",
      "\n",
      "The founders should be prepared to operate in a lean state for the next 6 months and make the most of their current resources. They should also be prepared to take calculated risks and adapt to changing market conditions.\n",
      "\n",
      "In contrast, Option A requires the founders to give up a significant equity stake and take on more risk, which may not be necessary given the current traction and growth rate. Option C is too aggressive and risky, as the founders will run out of runway quickly, leading to burnout and potential exit.\n",
      "\n",
      "Overall, Option B offers a balanced approach that allows the founders to grow the business, maintain control, and reduce the risk of dilution.\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 7Ô∏è‚É£ Prompt Engineering Best Practices & Tips\n",
    "\n",
    "### **üéØ The Golden Rules of Prompt Engineering:**\n",
    "\n",
    "#### **1. Clarity is King**\n",
    "- Use simple, clear language\n",
    "- Avoid ambiguous terms\n",
    "- Be specific about what you want\n",
    "\n",
    "#### **2. Context is Crucial**\n",
    "- Provide relevant background information\n",
    "- Set the scene for your request\n",
    "- Include constraints and requirements\n",
    "- How to get the context you may ask?\n",
    "![RAGS](https://m.media-amazon.com/images/I/91k5FXf3d6L.jpg)\n",
    "\n",
    "#### **3. Examples Are Powerful**\n",
    "- Show, don't just tell\n",
    "- Use diverse examples\n",
    "- Include edge cases when relevant\n",
    "\n",
    "#### **4. Structure Matters**\n",
    "- Use clear formatting and organization\n",
    "- Break complex tasks into steps\n",
    "- Specify desired output format\n",
    "\n",
    "#### **5. Iterate and Refine**\n",
    "- Start simple, then add complexity\n",
    "- Test variations of your prompts\n",
    "- Learn from what works and what doesn't\n",
    "\n",
    "#### **6. Know Your Model**\n",
    "- Modern models like Llama-3.2 and Phi-3 are highly capable\n",
    "- They understand context and nuance well\n",
    "- They respond excellently to reasoning prompts\n",
    "\n",
    "### **‚ö° Pro Tips for Better Results:**\n",
    "- Use \"Let's think step by step\" for complex problems\n",
    "- Add \"You are an expert in...\" for specialized knowledge\n",
    "- Include \"Be specific and detailed\" for comprehensive answers\n",
    "- Use \"Format your response as...\" for structured output\n",
    "- Try \"First..., then..., finally...\" for multi-step tasks\n",
    "\n",
    "### **üö´ Common Mistakes to Avoid:**\n",
    "- Being too vague in your requests\n",
    "- Not providing enough context\n",
    "- Asking multiple unrelated questions in one prompt\n",
    "- Forgetting to specify the desired output format\n",
    "- Not testing your prompts with variations"
   ],
   "id": "3089e083207a47b8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T04:49:40.463732Z",
     "start_time": "2025-07-17T04:49:40.445992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"üéì Practical Exercise: Design Your Own Prompts\")\n",
    "\n",
    "# Exercise: Create different prompts for the same task\n",
    "task = \"Help someone create a comprehensive business plan for a food truck\"\n",
    "prompts_to_test = [\n",
    "\n",
    "\n",
    "]\n",
    "# Design prompts using different techniques!\n",
    "# Example prompts:\n",
    "# prompts_to_test = [\n",
    "#     (\"Basic\", \"How do I write a business plan for a food truck?\"),\n",
    "#\n",
    "#     (\"Specific + Context\", \"I want to start a gourmet burger food truck in Austin, Texas with $80,000 startup capital. Create a comprehensive business plan covering market analysis, financial projections, and operations.\"),\n",
    "#\n",
    "#     (\"Expert Role-playing\", \"You are a successful food truck entrepreneur and business consultant with 10 years of experience. Help me create a detailed business plan for a gourmet burger food truck in Austin, Texas with $80,000 startup capital. Include specific insights from your experience.\"),\n",
    "#\n",
    "#     (\"Zero-shot CoT\", \"I need a business plan for a gourmet burger food truck in Austin, Texas with $80,000 startup capital. Let's think step by step about all the components I need to address.\"),\n",
    "#      ]\n",
    "\n",
    "print(\"\\nüîç Testing Different Prompt Approaches for Business Plan:\")\n",
    "for approach, prompt in prompts_to_test:\n",
    "    response = generate_llama_response(prompt, max_new_tokens=150)\n",
    "    print(f\"\\nüìù {approach}:\")\n",
    "    print(f\"Response: {response}\")\n",
    "    print(\"-\" * 50)"
   ],
   "id": "dc94b55865ae0db9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéì Practical Exercise: Design Your Own Prompts\n",
      "\n",
      "üîç Testing Different Prompt Approaches for Business Plan:\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![Prompting](https://i.imgur.com/iaEypZu.png)",
   "id": "cbcbf6351449cf9d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Contributed by: Ali Habibullah\n",
    "\n"
   ],
   "id": "18ffb4ee7408268e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
